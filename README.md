# shapley_allocations

shapley_allocations is a Python library for computing exact symmetric [shapley](https://en.wikipedia.org/wiki/Shapley_value) allocations of coalitional games efficiently. It uses the matrix representation from Wang[^1] et al (2018) for the computation. 

## Installation

Request [pip](https://pip.pypa.io/en/stable/) to install shapley_allocations.

```bash
pip install shapley_allocations
```

## Usage

### Shapley Intuition
Suppose there is a game with $N=3$ coalitions, labelled $K_1, K_2, K_3$. Let their payoff function $v: 2^3 \rightarrow \mathbb{R}$ be such that 
$$ 
v(K) = 
\begin{array}{cc}
  \{ & 
    \begin{array}{cc}
      1 & K \in \{K_1, K_2, K_3\} \\
      2 & K \in \{K_1 \cup K_2, K_1 \cup K_3, K_2 \cup K_3\} \\
      3 & K = K_1 \cup K_2 \cup K_3
    \end{array}
\end{array}.
$$
The payoff function in this case expresses that the payoff value equals the number of coalitions. Thus in this case, a fair way to distribute the payoff for each coalitions marginal contribution to the system payoff is by rewarding each participating coalition a unit of the payoff. It is not always the case that the marginal contibution is additive in this way, and that is where the Shapley allocations is introduced to handle such cases.

### Emission Examples
Our examples are motivated by the problem of carbon emission and pricing of power producing generators in the electric grid. As a result, our clusters are some arbitrary subset of generators -- possibly in the same region -- and our *payoffs* are the emissions generated by those subsets in some time frame.

Additionally, our emissions data is generated via Monte Carlo simulations due to randomness in the way the data is processed. For this reason, there is a distribution of emissions for some time frame. We simply take the worst case emissions and average them (i.e. [CVaR](https://en.wikipedia.org/wiki/Expected_shortfall))


### Determining the worst case simulations
One way that we optimize the code, in terms of memory, is that we only focus on the worst case simulations. For instance, if there are 500 simulations, and we want the 5\% worst simulations, we are left with 25 simulations

```python
from shapley_allocations.shapley import gen_bau_scen, tail_sims

# First, we create a dataframe that reads in csv files from a folder path. The number of .csv files are the num_scen. We specify what the index of the csv files should be, and also the columns of interest if we do not want all columns
folder_path = "root/directory"
num_scen = 500
indx = "Hour" #Does not have to be a unique index, we choose hourly because we perform groupby operations to obtain the houry sum
output_cols = ["CO2 Emissions metric ton", "Dispatch"]

#Returns a dataframe with the emission rate for each hour in all scenarios
bau_df = gen_bau_scen(self.folder_path, self.num_scen, [self.indx[1]],self.output_cols)


#Next, we filter out the highest emission rates
alpha = 0.05
indx = ["Scenario", "Hour"] #We use a multi-index now because we want the output specfying for each hour, the 100*alpha % worst case scenarios.

#The output of this is a list of the (Scenario, Hour) pairs that show the worst case simulations
tail_scen = tail_sims(alpha, bau_df, indx, "Output") #The final parameter is an arbitrary column name for 
```

### Clustering and Shapley Allocation
For now, any meaningful clustering is completed outside of the code. This is to keep the program flexible. Users are able to import their premade clusters into a dataframe.

There is capabilities of crude clustering: given a dataframe of $I$ unique id's, the 
'''python 
gen_cohort(num_cohorts, fname, indx)
'''
can cluster the players into $N=I/K$ even clusters.

```python
from shapley_allocations.shapley import gen_bau_scen, tail_sims

# First, we read in the cohorts file. This is a csv with two columns. The first column is the ID of the player and the second column is the corresponding cluser they are in.
cluster_fname = "root/directory_to_cohort.csv"

#Returns a dataframe of the cohorts
cohorts = pd.read_csv(cluster_fname, header = 0, index_col = 0)

#Next, we compute our payoffs into what is called the characteristic matrix. 
#The next function computes the emission rate in each coalition (2^N) for the worst case scenarios


num_cohorts = 3
sec_asset_id = "Generator"

#Outputs a 3-D matrix, where the depth is corresponds to the number of worst case scenarios. The rows correspond to hours and the columns correspond to a particular coalition
char_matrix = gen_cohort_payoff(num_cohorts, cohorts.squeeze(), folder_path,
                tail_scen, sec_asset_id, indx, output_cols)

#We are not ready to compute the shapley and average them over the worst case scenarios
result = shap(char_matrix, num_cohorts, np.ceil(alpha*num_scen))
pd.DataFrame(result).to_csv(output_file)
```

## Contributing

Pull requests are welcome. For major changes, please open an issue first
to discuss what you would like to change.

Please make sure to update tests as appropriate.

## License

[MIT](https://choosealicense.com/licenses/mit/)

## References
[^1]: Wang, Y., Cheng, D. & Liu, X. Matrix expression of Shapley values and its application to distributed resource allocation. Sci. China Inf. Sci. 62, 22201 (2019). https://doi.org/10.1007/s11432-018-9414-5